# -*- coding: utf-8 -*-
"""neural_network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dK-GmBleT5spQpXqFdbWAQmUtbERz4w4
"""

import numpy as np
from sklearn.metrics import classification_report


class FCLayer:
    def __init__(self, input_size, output_size):
        self.input_size = input_size
        self.output_size = output_size
        self.weights = np.random.randn(input_size, output_size) / np.sqrt(input_size + output_size)
        self.bias = np.random.randn(1, output_size) / np.sqrt(input_size + output_size)

    def forward(self, input):
        self.input = input
        return np.dot(input, self.weights) + self.bias

    def backward(self, output_error, learning_rate):
        input_error = np.dot(output_error, self.weights.T)
        weights_error = np.dot(self.input.T, output_error)
        # bias_error = output_error
        
        self.weights -= learning_rate * weights_error
        self.bias -= learning_rate * output_error
        return input_error

class ActivationLayer:
    def __init__(self, activation, activation_prime):
        self.activation = activation
        self.activation_prime = activation_prime
    
    def forward(self, input):
        self.input = input
        return self.activation(input)
    
    def backward(self, output_error, learning_rate):
        return output_error * self.activation_prime(self.input)

class FlattenLayer:
    def __init__(self, input_shape):
        self.input_shape = input_shape

    def forward(self, input):
        return np.reshape(input, (1, -1))
    
    def backward(self, output_error, learning_rate):
        return np.reshape(output_error, self.input_shape)

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_prime(x):
    return np.exp(-x) / (1 + np.exp(-x))**2

def tanh(x):
    return np.tanh(x)

def tanh_prime(x):
    return 1 - np.tanh(x)**2

def relu(x):
    return np.maximum(x, 0)

def relu_prime(x):
    return np.array(x >= 0).astype('int')

def rectifier(x):
    if np.all(x) <= 0:
        return 0
    else:      
        return x

def rectifier_prime(x):
    if np.all(x) <= 0:
        return 0
    else:
        return 1

def predict(network, input):
    output = input
    for layer in network:
        output = layer.forward(output)
    return output

def mse(y_true, y_pred):
    return np.mean(np.power(y_true - y_pred, 2))

def mse_prime(y_true, y_pred):
    return 2 * (y_pred - y_true) / y_pred.size


def test_network(network,x_test,y_test):
    labels = []
    prediction = []
    for test, true in zip(x_test, y_test):
      pred = predict(network, test)[0]
      idx = np.argmax(pred)
      idx_true = np.argmax(true)
      labels.append(idx_true)
      prediction.append(idx)

    print('********Classification Report********\n')
    print(classification_report(prediction, labels))

def print_digit(t):
    import sys
    dat = t.reshape((28, 28))
    for k in range(28):
        for j in range(28):
            if dat[k][j]>0:
                sys.stdout.write("#")
            else:
                sys.stdout.write(".")
            sys.stdout.flush()
        sys.stdout.write("\n")










